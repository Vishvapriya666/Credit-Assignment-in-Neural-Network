{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDigMNLyGD1JKm5mTzovtf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5l6hNo3n5vDe","executionInfo":{"status":"ok","timestamp":1697702020847,"user_tz":-330,"elapsed":559,"user":{"displayName":"Vishvapriya.Sangvikar Btech2020","userId":"15384214507861777984"}}},"outputs":[],"source":["#This is the neural network assignment number 4\n","\n","#this is the experiment 10\n","''' Study and Implementation of Credit Assignment Problem.\n","Problem Statement: Develop a game sing Reinforcement learning (Q learning).\n","Rules are as follows Traveler has 8\n","degrees of movement. Up, down, left and right.\n","Create a maze as discussed in the class.'''\n","\n","\n","#Importing the important libraries\n","import numpy as np\n","import pandas as pd\n","import os"]},{"cell_type":"code","source":["import numpy as np\n","\n","# Define the maze\n","maze = np.array([\n","    [\"S\", \" \", \"#\", \" \", \" \", \"#\", \" \", \"G\"],\n","    [\" \", \"#\", \" \", \" \", \"#\", \" \", \"#\", \" \"],\n","    [\" \", \"#\", \"#\", \" \", \" \", \"#\", \" \", \" \"],\n","    [\" \", \" \", \" \", \"#\", \" \", \" \", \" \", \" \"],\n","    [\" \", \"#\", \" \", \" \", \" \", \"#\", \"#\", \" \"],\n","    [\" \", \" \", \"#\", \"#\", \" \", \" \", \" \", \" \"],\n","    [\"#\", \" \", \" \", \"#\", \" \", \"#\", \" \", \" \"],\n","    [\" \", \" \", \"#\", \" \", \" \", \" \", \"#\", \" \"]\n","])\n","\n","# Define rewards\n","rewards = {\"G\": 100, \"#\": -100, \"default\": -1}\n","\n","# Define possible movements\n","movements = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (-1, 1), (1, -1), (-1, -1)]\n","\n","# Initialize Q-values\n","Q_values = np.zeros((maze.shape[0], maze.shape[1], len(movements)))\n","\n","# Define parameters\n","learning_rate = 0.8\n","discount_factor = 0.95\n","exploration_prob = 0.2\n","epochs = 1000\n","\n","# Q-learning algorithm\n","for epoch in range(epochs):\n","    current_state = (0, 0)  # Starting position\n","    while True:\n","        # Choose an action (movement) using epsilon-greedy strategy\n","        if np.random.uniform(0, 1) < exploration_prob:\n","            action = np.random.choice(len(movements))\n","        else:\n","            action = np.argmax(Q_values[current_state[0], current_state[1]])\n","\n","        # Perform the action and get the next state and reward\n","        movement = movements[action]\n","        next_state = (current_state[0] + movement[0], current_state[1] + movement[1])\n","\n","        # Check if the next state is valid\n","        if 0 <= next_state[0] < maze.shape[0] and 0 <= next_state[1] < maze.shape[1] and maze[next_state] != \"#\":\n","            reward = rewards.get(maze[next_state], rewards[\"default\"])\n","        else:\n","            next_state = current_state\n","            reward = rewards[\"#\"]\n","\n","        # Update Q-value for the current state and action\n","        Q_values[current_state[0], current_state[1], action] = (1 - learning_rate) * Q_values[current_state[0], current_state[1], action] + learning_rate * (reward + discount_factor * np.max(Q_values[next_state[0], next_state[1]]))\n","\n","        # Move to the next state\n","        current_state = next_state\n","\n","        # Check if the goal is reached or hit the maximum number of steps\n","        if maze[current_state] == \"G\" or maze[current_state] == \"#\":\n","            break\n","\n","# Print the learned Q-values\n","print(\"Learned Q-values:\")\n","print(Q_values)\n","\n","# Function to find the optimal path using learned Q-values\n","def find_optimal_path(start):\n","    path = []\n","    current_state = start\n","    while True:\n","        action = np.argmax(Q_values[current_state[0], current_state[1]])\n","        movement = movements[action]\n","        next_state = (current_state[0] + movement[0], current_state[1] + movement[1])\n","        path.append(next_state)\n","        if maze[next_state] == \"G\":\n","            break\n","        current_state = next_state\n","    return path\n","\n","# Find and print the optimal path from the start to the goal\n","optimal_path = find_optimal_path((0, 0))\n","print(\"Optimal Path:\")\n","print(optimal_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZq0NIsS7Aod","executionInfo":{"status":"ok","timestamp":1697702026242,"user_tz":-330,"elapsed":623,"user":{"displayName":"Vishvapriya.Sangvikar Btech2020","userId":"15384214507861777984"}},"outputId":"5fea1b6d-c0e3-45aa-8f2a-09488bb835b7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Learned Q-values:\n","[[[  68.21102687  -35.19952447   59.61045175  -35.19952447  -35.19952447\n","    -35.19952447  -35.19952447  -35.19952447]\n","  [ -30.78897313   63.80047553  -30.78897313  -30.78897313   72.8537125\n","    -30.78897313   59.61045175  -30.78897313]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  -2.570752    -40.72263099   61.6884336   -40.6311785   -32.7574142\n","    -31.18266134   72.8537125   -80.        ]\n","  [ -18.6704       -2.397696    -17.3915391   -80.           88.3\n","    -28.892        61.6109168   -16.217216  ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [ 100.           -5.           -5.           -5.           94.\n","     -5.           88.3          -5.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]]\n","\n"," [[ -39.84243186  -41.01396632   35.65418988   63.80047553  -41.7285684\n","     33.11327112  -51.36111641  -52.02543641]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  77.74075     -26.1462875   -26.1462875   -26.1462875    77.74075\n","     68.21102687  -26.1462875    68.21102687]\n","  [ -21.25925      72.8537125    77.74075      68.21102687   82.885\n","     82.885       -21.25925     -21.25925   ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [ -10.7         -10.7         -10.7         -10.7          88.3\n","     94.           82.885        82.885     ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [ -20.           -8.           85.851904    100.            0.\n","     -4.96         70.64         93.96992   ]]\n","\n"," [[ -80.          -97.82224896   -4.74403428   -4.77648084   63.58531878\n","    -80.          -80.          -80.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  82.885       -21.73633468  -21.26300941   74.51623949   70.92124659\n","    -21.3532352    72.765948     72.73226242]\n","  [ -16.115        77.74075      72.8537125   -16.115        82.885\n","     88.3         -16.115        77.74075   ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  81.7080832   -10.81088002   82.20462862  -13.472        69.86502584\n","     94.           82.751104     70.48      ]\n","  [ -80.           -0.96         57.28023928   93.969664    -80.\n","    -38.9696       -0.8         -80.        ]]\n","\n"," [[  -4.42545103  -80.           -4.50180492   -4.54716937  -98.92890655\n","    -80.          -96.608       -96.608     ]\n","  [  72.62705784   -4.00157893 -100.605696    -98.83611513   -3.98581391\n","    -80.           -3.93179955   -4.82322298]\n","  [ -41.8620799    -4.30074601   -4.18302149  -80.           -3.34010368\n","     77.74070854  -80.          -80.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  65.8408      -80.           77.74075      65.845664    -36.91703671\n","    -40.37871455   57.14512834   77.09847507]\n","  [  -1.6          57.80260986  -16.78921859  -97.19168     -16.62608\n","     88.3          74.56334848   82.2084032 ]\n","  [  61.65240943   -1.568       -80.           88.29988643   -1.7216\n","     -0.8         -28.89243158  -80.        ]\n","  [ -96.           82.58685451   23.72957184   -1.568       -96.\n","    -80.          -80.           -1.568     ]]\n","\n"," [[ -96.75392     -99.95392      -3.92114995   -4.55585253   -3.87239649\n","     32.79587474  -80.          -80.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  -3.46158694  -80.          -80.           57.59616863  -98.4331518\n","    -80.           -3.94713866   -3.69928192]\n","  [  77.60826663   -3.036416    -40.62046679 -100.0512       -3.0130688\n","     -3.0610432   -97.7520128    -3.97936858]\n","  [ -36.2074       64.78537171   -3.0130688    -2.36032      -2.446336\n","     82.885       -80.          -36.329     ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [ -80.          -97.19168      -2.428416     -1.7216      -96.7296\n","    -80.           -2.6807808    72.8499189 ]]\n","\n"," [[  -3.56092928  -96.         -100.90317824   -4.44093661   -3.77890652\n","    -80.          -98.15685325  -80.        ]\n","  [ -99.808        -3.61654682   -3.36965427  -80.           -3.67873229\n","     -3.45849037  -80.           -3.8106751 ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  -2.428416   -100.51328      -2.637568     -2.661888    -80.\n","    -80.          -80.           -3.29911091]\n","  [  -2.520832     -2.36032     -80.          -80.           -2.3296\n","    -80.           -2.15168      61.70186448]\n","  [  -2.9692928    -2.31168      -2.9206528   -80.           -2.8218368\n","     -2.452736    -80.          -80.        ]\n","  [ -99.2          -3.0143488    -2.397696     -2.428416    -80.\n","    -80.           -2.3296      -80.        ]]\n","\n"," [[   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  -3.88828815  -80.           -3.67529165   -3.40187341  -80.\n","    -80.           -3.74577766   -3.3191895 ]\n","  [ -80.           -3.69721549  -80.          -80.           -3.81881385\n","    -96.608        -3.30743808   -3.19906816]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [ -97.19168     -80.           -3.06598912   -2.8282368    -2.99088896\n","     -2.9011968    -3.74336512  -80.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  -2.6628608   -96.          -80.           -2.613248     -3.0130688\n","     -2.9206528    -2.569472     -2.446336  ]\n","  [ -97.19168      -2.520832     -3.0130688    -2.35392     -96.608\n","    -80.          -80.           -2.422016  ]]\n","\n"," [[  -3.75997276  -80.          -96.          -80.          -96.608\n","     -3.90853878  -80.          -80.        ]\n","  [ -80.           -3.68768205  -97.7520128    -3.17353779  -80.\n","     -3.72032922  -80.          -80.        ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [  -3.24943872  -96.          -96.          -80.          -97.216\n","     -3.2052736   -80.           -3.49273293]\n","  [  -3.13614336   -3.49709517  -80.           -2.663168    -97.216\n","    -97.308416    -80.          -80.        ]\n","  [ -80.           -2.452736    -80.          -80.          -96.\n","     -2.852864    -80.           -2.939136  ]\n","  [   0.            0.            0.            0.            0.\n","      0.            0.            0.        ]\n","  [ -80.          -80.          -80.           -3.0130688   -80.\n","    -80.          -80.           -3.0130688 ]]]\n","Optimal Path:\n","[(0, 1), (1, 2), (1, 3), (2, 4), (1, 5), (0, 6), (0, 7)]\n"]}]},{"cell_type":"code","source":["#Exp 11 : (18/9/23)\n","#Aim: To design and simulate a Backpropagation training algorithm for multi-layer continuous perception.\n","#Problem Statement:  Implement BPA to train XOR problem.\n","\n","import numpy as np\n","\n","# Sigmoid activation function and its derivative\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Input data for XOR problem\n","input_data = np.array([[0, 0],\n","                       [0, 1],\n","                       [1, 0],\n","                       [1, 1]])\n","\n","# Expected output for XOR problem\n","output_data = np.array([[0],\n","                        [1],\n","                        [1],\n","                        [0]])\n","\n","# Seed for reproducibility\n","np.random.seed(42)\n","\n","# Initialize weights randomly with mean 0\n","input_neurons = 2\n","hidden_neurons = 2\n","output_neurons = 1\n","learning_rate = 0.1\n","epochs = 10000\n","\n","# Initialize weights with mean 0\n","weights_input_hidden = 2 * np.random.random((input_neurons, hidden_neurons)) - 1\n","weights_hidden_output = 2 * np.random.random((hidden_neurons, output_neurons)) - 1\n","\n","# Training the neural network\n","for epoch in range(epochs):\n","    # --- Forward Propagation ---\n","    # Input layer to hidden layer\n","    hidden_input = np.dot(input_data, weights_input_hidden)\n","    hidden_output = sigmoid(hidden_input)\n","\n","    # Hidden layer to output layer\n","    output_input = np.dot(hidden_output, weights_hidden_output)\n","    predicted_output = sigmoid(output_input)\n","\n","    # --- Backpropagation ---\n","    # Calculate error\n","    error = output_data - predicted_output\n","\n","    # Output layer to hidden layer (Backpropagation)\n","    output_delta = error * sigmoid_derivative(predicted_output)\n","    hidden_error = output_delta.dot(weights_hidden_output.T)\n","    hidden_delta = hidden_error * sigmoid_derivative(hidden_output)\n","\n","    # Update weights using gradient descent\n","    weights_hidden_output += hidden_output.T.dot(output_delta) * learning_rate\n","    weights_input_hidden += input_data.T.dot(hidden_delta) * learning_rate\n","\n","# Test the trained neural network\n","test_input = np.array([[0, 0],\n","                       [0, 1],\n","                       [1, 0],\n","                       [1, 1]])\n","\n","predicted_output = sigmoid(np.dot(sigmoid(np.dot(test_input, weights_input_hidden)), weights_hidden_output))\n","print(\"Predicted Output:\")\n","print(predicted_output)\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mY42dO3y902G","executionInfo":{"status":"ok","timestamp":1697702760663,"user_tz":-330,"elapsed":515,"user":{"displayName":"Vishvapriya.Sangvikar Btech2020","userId":"15384214507861777984"}},"outputId":"07cc3b0d-fedd-4e91-b465-56956f858ec6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Output:\n","[[0.26673682]\n"," [0.68495836]\n"," [0.68506721]\n"," [0.40638174]]\n"]}]}]}